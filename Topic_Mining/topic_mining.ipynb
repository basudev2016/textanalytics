{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "random_state = 0\n",
    "DATA_DIR = \"C:\\\\Users\\\\bpanda8\\\\OneDrive - DXC Production\\\\Desktop\\\\Text_Analytics\\\\Topic Mining\\\\bbc\"\n",
    "data = load_files(DATA_DIR, encoding=\"utf-8\", decode_error=\"replace\", random_state=random_state)\n",
    "df = pd.DataFrame(list(zip(data['data'], data['target'])), columns=['text', 'label'])\n",
    "df.shape\n",
    "# df.to_csv('bbc_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boss award executive business magazine title p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>copy bumper sale fi shooter game copy sale com...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>climate warning climate change control decade ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>success week race track bronze injury season i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tory rethink association candidate election ag...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  boss award executive business magazine title p...      0\n",
       "1  copy bumper sale fi shooter game copy sale com...      4\n",
       "2  climate warning climate change control decade ...      2\n",
       "3  success week race track bronze injury season i...      3\n",
       "4  tory rethink association candidate election ag...      2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def only_nouns(texts):\n",
    "    output = []\n",
    "    for doc in nlp.pipe(texts):\n",
    "        noun_text = \" \".join(token.lemma_ for token in doc if token.pos_ == 'NOUN')\n",
    "        output.append(noun_text)\n",
    "    return output\n",
    "\n",
    "\n",
    "df['text'] = only_nouns(df['text'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(n_components=5, random_state=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of topics to extract\n",
    "## NMF = Non-Negative Matrix Factorization\n",
    "n_topics = 5\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vec = TfidfVectorizer(max_features=5000, stop_words=\"english\", max_df=0.95, min_df=2)\n",
    "features = vec.fit_transform(df.text)\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "cls = NMF(n_components=n_topics, random_state=random_state)\n",
    "cls.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 growth sale economy year company share market rate firm price \n",
      "1 game player match team injury club time coach win season \n",
      "2 film award actor actress star director nomination movie year festival \n",
      "3 election party government tax minister leader people campaign chancellor plan \n",
      "4 phone people technology music service user software computer broadband network \n"
     ]
    }
   ],
   "source": [
    "# list of unique words found by the vectorizer\n",
    "feature_names = vec.get_feature_names()\n",
    "\n",
    "# number of most influencing words to display per topic\n",
    "n_top_words = 10\n",
    "\n",
    "for i, topic_vec in enumerate(cls.components_):\n",
    "    print(i, end=' ')\n",
    "    # topic_vec.argsort() produces a new array\n",
    "    # in which word_index with the least score is the\n",
    "    # first array element and word_index with highest\n",
    "    # score is the last array element. Then using a\n",
    "    # fancy indexing [-1: -n_top_words-1:-1], we are\n",
    "    # slicing the array from its end in such a way that\n",
    "    # top `n_top_words` word_index with highest scores\n",
    "    # are returned in desceding order\n",
    "    for fid in topic_vec.argsort()[-1:-n_top_words-1:-1]:\n",
    "        print(feature_names[fid], end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_articles = [\n",
    "    \"The owner of Apple and Microsoft likes rugby\"]\n",
    "    \n",
    "# first transform the text into features using vec\n",
    "# then pass it to transform of cls\n",
    "# the result will be a matrix of shape [2, 10]\n",
    "# then we sort the topic id based on the score using argsort\n",
    "# and take the last one (with the highest score) for each row using `[:,-1]` indexing\n",
    "cls.transform(vec.transform(new_articles)).argsort(axis=1)[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA\n",
    "LSA\n",
    "RNN\n",
    "BERT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
